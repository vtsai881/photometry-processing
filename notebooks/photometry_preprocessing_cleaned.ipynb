{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45aa5cfa",
   "metadata": {},
   "source": [
    "# Photometry Preprocessing Notebook\n",
    "1. import packages\n",
    "2. load functions\n",
    "3. process your folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7474aa",
   "metadata": {},
   "source": [
    "### 1. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d213860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow\n",
    "from pyarrow import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5117b9",
   "metadata": {},
   "source": [
    "### 2. load functions (run both function definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fe9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_consecutive(input_list, limit=5):\n",
    "    result = [input_list[0]] \n",
    "\n",
    "    for value in input_list[1:]:\n",
    "        if abs(value - result[-1]) > limit:\n",
    "            result.append(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_one_folder(folder, method, trialtype):\n",
    "    dcol = ['D' + str(i) for i in range(128)]\n",
    "\n",
    "    rewardtrials = []\n",
    "    ititrials = []\n",
    "    puntrials = []\n",
    "\n",
    "    \n",
    "    if trialtype == 'rt':\n",
    "        rewardtrials = [x for x in range(1, 38)]\n",
    "    \n",
    "    elif trialtype == 'rn':\n",
    "        rewardtrials = [0, 2, 3, 4, 6, 8, 10, 12, 14, 15, 16, 18, 20, 22, 24, 26, 27, 28, 29, 30, 32, 34, 36, 38, 40, 42, 44, 46, 47, 48, 50]\n",
    "        ititrials = [1, 5, 7, 9, 11, 13, 17, 19, 21, 23, 25, 31, 33, 35, 37, 39, 41, 43, 45, 49]\n",
    "        \n",
    "        rewardtrials = [x + 1 for x in rewardtrials]\n",
    "        ititrials = [x + 1 for x in ititrials]\n",
    "    \n",
    "    elif trialtype == 'rnp':\n",
    "        \n",
    "        df2 = pd.read_csv(r\"C:\\Users\\tsaivs\\Downloads\\Rew_Neutral_Pun_HEY1.csv\", header=None)\n",
    "        trials = df2.iloc[:,1]\n",
    "        for i in range(0, len(df2.iloc[:,1])):\n",
    "            if (df2.iloc[:,1][i] == 'p'):\n",
    "                puntrials.append(i + 1)\n",
    "            elif (df2.iloc[:,1][i] == 'i'):\n",
    "                ititrials.append(i + 1)\n",
    "            elif (df2.iloc[:,1][i] == 't'):\n",
    "                rewardtrials.append(i + 1)\n",
    "    \n",
    "    if method == 'guppy':\n",
    "        for file in os.listdir(folder):\n",
    "            cur_csv = os.path.join(folder,file)\n",
    "            df = pd.read_csv(cur_csv)\n",
    "            print(file)\n",
    "\n",
    "            if file.startswith('TTL'):\n",
    "\n",
    "                df['ttls'] = df[dcol].max(axis=1)\n",
    "\n",
    "                newdf = pd.DataFrame()\n",
    "                t = list(df['TIME'].loc[df['ttls'] == 1])\n",
    "                if (len(t) == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    newdf['timestamps'] = remove_consecutive(t, limit=8.5)\n",
    "                    newdf = newdf.reset_index(drop=True)\n",
    "\n",
    "                    rew = newdf.iloc[rewardtrials]\n",
    "                    iti = newdf.iloc[ititrials]\n",
    "                    pun = newdf.iloc[puntrials]\n",
    "\n",
    "                    newdf.to_csv(os.path.join(folder,'TTL_guppy_processed_2.csv'), index=None)\n",
    "                    rew.to_csv(os.path.join(folder, 'rew_TTL_guppy_processed.csv'), index=None)\n",
    "                    iti.to_csv(os.path.join(folder, 'neutral_TTL_guppy_processed.csv'), index=None)\n",
    "                    pun.to_csv(os.path.join(folder, 'pun_TTL_guppy_processed.csv'), index=None)\n",
    "                \n",
    "            elif file.startswith('405') or file.startswith('470'):\n",
    "                hz =  1 / df['Sampling_Freq'][0] \n",
    "                newdf = pd.DataFrame({'data': df[dcol].to_numpy().flatten(), 'sampling_rate': df['Sampling_Freq'][0]})\n",
    "                newdf['timestamps'] = newdf.index * hz\n",
    "                newdf['sampling_rate'][1:] = None\n",
    "                newdf = newdf[['timestamps', 'data' , 'sampling_rate']]\n",
    "                newdf_ = pyarrow.Table.from_pandas(newdf)\n",
    "                pyarrow.csv.write_csv(newdf_, os.path.join(folder, file.split('.')[0] + '_guppy_processed.csv') )\n",
    "    \n",
    "    elif method == 'pmat':\n",
    "        df_405 = pd.read_csv(os.path.join(folder,'405.csv'))\n",
    "        df_470 =  pd.read_csv(os.path.join(folder,'470.csv'))\n",
    "\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['TimeStamp'] = df_470['TIME'].copy()\n",
    "        newdf['Signal'] = df_470[dcol].mean(axis=1)\n",
    "        newdf['Control'] = df_405[dcol].mean(axis=1)\n",
    "\n",
    "        newdf.to_csv(os.path.join(folder,'pmat_processed.csv'))\n",
    "    \n",
    "    elif method == 'pmatttl':\n",
    "        df_ttl = pd.read_csv(os.path.join(folder,'TTL.csv'))\n",
    "        df_405 = pd.read_csv(os.path.join(folder,'405.csv'))\n",
    "        df_470 =  pd.read_csv(os.path.join(folder,'470.csv'))\n",
    "\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['TimeStamp'] = df_470['TIME'].copy()\n",
    "        newdf['Signal'] = df_470[dcol].mean(axis=1)\n",
    "        newdf['Control'] = df_405[dcol].mean(axis=1)\n",
    "        newdf['ttls'] = df_ttl[dcol].max(axis=1)\n",
    "\n",
    "        firstidx = np.where(newdf.ttls == 1)[0][0]\n",
    "\n",
    "        newdf['TimeStamp'] -= newdf['TimeStamp'][firstidx]\n",
    "        newdf = newdf[['TimeStamp', 'Signal', 'Control']][firstidx:].reset_index(drop=True)\n",
    "\n",
    "        newdf.to_csv(os.path.join(folder,'pmat_ttl_processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e03636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_folders(folders, method, trialtype):\n",
    "    \n",
    "    for root, directories, files in os.walk(folders):\n",
    "        for directory in directories:\n",
    "            directory_path = os.path.join(root, directory)\n",
    "            # if all three files exists\n",
    "            required_strings = ('405', '470', 'TTL')\n",
    "            if all(any(string in filename for filename in os.listdir(directory_path)) for string in required_strings):\n",
    "                process_one_folder(directory_path, method, trialtype)\n",
    "            \n",
    "            print(f'Processed: {directory_path} with {method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf41d7d",
   "metadata": {},
   "source": [
    "### 3. processing\n",
    "- there are two functions: `process_one_folder()` and `process_all_folders()`\n",
    "- `process_one_folder()` will process the contents of a folder of raw data extracted from synapse\n",
    "- `process_one_folder()` must be given 3 arguments: (**filepath**, **processing_method**, **trialtype**)\n",
    "- **filepath**: path to your folder or directory of folders\n",
    "- **processing_method**: either *'guppy'*, *'pmat'*, or *'pmatttl'*\n",
    "-*'guppy'* formats for processing in GuPPy\n",
    "- *'pmat'* formats for processing in PMAT,\n",
    "-*'pmatttl'* formats for processing in pmat and aligns data to the first ttl\n",
    "- **trialtype**: exclusive to guppy processing, specify if the trialtypes are reward only (*'rt'*), reward/neutral (*'rn'*), or reward/neutral/punishment (*'rnp'*)\n",
    "        -folder must contain files named 405.csv, 470.csv, and TTL.csv\n",
    "- `process_all_folders()` will iteratively process all folders and subfolders within a directory that can be processed with `process_one_folder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3672ff9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.58 s\n",
      "Wall time: 4.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_one_folder(r'C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1018_cohort\\test\\rew_neutral_punish\\RNP_D3\\99_3', 'guppy', 'rnp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199a7af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD1_umass with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD2_umass with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD3_umass with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD1_umass\\47_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD1_umass\\47_3 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD1_umass\\48_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD1_umass\\48_2 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD2_umass\\47_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD2_umass\\47_3 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD2_umass\\48_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD2_umass\\48_2 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD3_umass\\47_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD3_umass\\47_3 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD3_umass\\48_1 with guppy\n",
      "Processed: C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\\Raw_Photom_Data\\RTD3_umass\\48_2 with guppy\n",
      "CPU times: total: 44.5 s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folder = r\"C:\\Users\\Valerie\\Documents\\Tejeda_Lab\\headfixed\\1130_umass\"\n",
    "\n",
    "process_all_folders(folder, 'guppy', 'rnp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
